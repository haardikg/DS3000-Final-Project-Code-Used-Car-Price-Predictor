{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "b8E5iQoTh-LT",
        "outputId": "571b4865-80fe-47c5-f972-554e23b697e5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/cars.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOpP9x1R2aMf"
      },
      "source": [
        "#CLEANING NORMALIZING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1afB8OaXx7gU"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------------\n",
        "# 1. CLEANING (your rules)\n",
        "# -------------------------------------------------------------------\n",
        "df = df.drop(columns=['seller_name', 'seller_rating'])\n",
        "df = df.dropna(subset=['driver_rating', 'mileage'])\n",
        "\n",
        "df['exterior_color']  = df['exterior_color'].fillna('Unknown')\n",
        "df['engine']          = df['engine'].fillna('Unknown')\n",
        "df['transmission']    = df['transmission'].fillna('Unknown')\n",
        "df['interior_color']  = df['interior_color'].fillna('Unknown')\n",
        "\n",
        "df['accidents_or_damage_missing'] = df['accidents_or_damage'].isna().astype(int)\n",
        "df['accidents_or_damage'] = df['accidents_or_damage'].fillna(0)\n",
        "\n",
        "df['one_owner_missing'] = df['one_owner'].isna().astype(int)\n",
        "df['one_owner'] = df['one_owner'].fillna(1)\n",
        "\n",
        "df['personal_use_only_missing'] = df['personal_use_only'].isna().astype(int)\n",
        "df['personal_use_only'] = df['personal_use_only'].fillna(1)\n",
        "\n",
        "df['drivetrain'] = df['drivetrain'].fillna('Missing')\n",
        "df['fuel_type']  = df['fuel_type'].fillna('Missing')\n",
        "df['mpg']        = df['mpg'].fillna('Missing')\n",
        "\n",
        "df['price_drop'] = df['price_drop'].fillna(0)\n",
        "df['driver_total_rating'] = df['driver_rating'] * df['driver_reviews_num']\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 2. TARGET AND FEATURES\n",
        "# -------------------------------------------------------------------\n",
        "print(\"Columns at this point:\", df.columns.tolist())  # sanity check\n",
        "\n",
        "df = df[df['price'] <= 75000]\n",
        "\n",
        "# optional: downsample to make everything faster (e.g. 100k rows)\n",
        "# df = df.sample(n=100000, random_state=42)\n",
        "\n",
        "y = df['price']               # if this line errors, price is really gone\n",
        "X = df.drop(columns=['price'])\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 3. ENCODING\n",
        "#    - low-cardinality categoricals: one-hot\n",
        "#    - high-cardinality: integer codes\n",
        "# -------------------------------------------------------------------\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "threshold = 50\n",
        "low_card = [c for c in cat_cols if X[c].nunique() <= threshold]\n",
        "high_card = [c for c in cat_cols if c not in low_card]\n",
        "\n",
        "for c in high_card:\n",
        "    X[c] = X[c].astype('category').cat.codes\n",
        "\n",
        "X = pd.get_dummies(X, columns=low_card, drop_first=True)\n",
        "\n",
        "print(\"Final feature shape:\", X.shape)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 4. TRAIN / VAL / TEST SPLIT (70 / 20 / 10)\n",
        "# -------------------------------------------------------------------\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=1/3, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Val:\",   X_val.shape)\n",
        "print(\"Test:\",  X_test.shape)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 5. STANDARDIZATION (for MLP)\n",
        "# -------------------------------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled   = scaler.transform(X_val)\n",
        "X_test_scaled  = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veTOWIJ10pnd"
      },
      "source": [
        "#GRADIENT BOOSTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2agDss0Ayt0a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjDs50nW0snE"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# Gradient Boosting for Car Price\n",
        "# =============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 7. Gradient Boosting model\n",
        "# ------------------------------------------------------\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "gbr = GradientBoostingRegressor(\n",
        "    n_estimators=150,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train with timing\n",
        "start = time.perf_counter()\n",
        "gbr.fit(X_train, y_train)\n",
        "train_time_s = time.perf_counter() - start\n",
        "print(f\"Training time: {train_time_s:.2f} s\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 8. Evaluation helpers\n",
        "# ------------------------------------------------------\n",
        "def evaluate(split_name, y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"--- {split_name} ---\")\n",
        "    print(f\"MAE : {mae:,.2f}\")\n",
        "    print(f\"RMSE: {rmse:,.2f}\")\n",
        "    print(f\"R^2 : {r2:.3f}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "#Train\n",
        "evaluate(\"Train\", y_train, gbr.predict(X_train))\n",
        "\n",
        "# Validation\n",
        "y_val_pred = gbr.predict(X_val)\n",
        "evaluate(\"Validation\", y_val, y_val_pred)\n",
        "\n",
        "# Test with timing\n",
        "start = time.perf_counter()\n",
        "y_test_pred = gbr.predict(X_test)\n",
        "test_time_s = time.perf_counter() - start\n",
        "\n",
        "evaluate(\"Test\", y_test, y_test_pred)\n",
        "print(f\"Test prediction time for {len(X_test)} samples: {test_time_s*1000:.2f} ms\")\n",
        "print(f\"Per-sample prediction time: {(test_time_s*1000)/len(X_test):.4f} ms\")\n",
        "\n",
        "\n",
        "train_mse = []\n",
        "val_mse = []\n",
        "\n",
        "for y_pred_train, y_pred_val in zip(\n",
        "    gbr.staged_predict(X_train),\n",
        "    gbr.staged_predict(X_val)\n",
        "):\n",
        "    train_mse.append(mean_squared_error(y_train, y_pred_train))\n",
        "    val_mse.append(mean_squared_error(y_val,   y_pred_val))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_mse, label=\"Train MSE\")\n",
        "plt.plot(val_mse,   label=\"Validation MSE\")\n",
        "plt.xlabel(\"Boosting iteration (number of trees)\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.title(\"Training vs Validation Loss (Gradient Boosting Regressor)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-Ml-TYH0u_F"
      },
      "source": [
        "#Mutliple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf8iYaGa0zh9"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# Multiple Linear Regression for Car Price\n",
        "# =============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 7. MULTIPLE LINEAR REGRESSION MODEL\n",
        "# -------------------------------------------------------------------\n",
        "mlr = LinearRegression()\n",
        "\n",
        "# Train\n",
        "mlr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = mlr.predict(X_train_scaled)\n",
        "y_val_pred   = mlr.predict(X_val_scaled)\n",
        "y_test_pred  = mlr.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 8. EVALUATION\n",
        "# -------------------------------------------------------------------\n",
        "def evaluate(split_name, y_true, y_pred):\n",
        "    mae  = mean_absolute_error(y_true, y_pred)\n",
        "    mse  = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2   = r2_score(y_true, y_pred)\n",
        "    print(f\"--- {split_name} ---\")\n",
        "    print(f\"MAE : {mae:,.2f}\")\n",
        "    print(f\"RMSE: {rmse:,.2f}\")\n",
        "    print(f\"R^2 : {r2:.3f}\")\n",
        "    print()\n",
        "\n",
        "evaluate(\"Train (MLR)\", y_train, y_train_pred)\n",
        "evaluate(\"Validation (MLR)\", y_val, y_val_pred)\n",
        "evaluate(\"Test (MLR)\", y_test, y_test_pred)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5To0vLiFB6U"
      },
      "source": [
        "# Random Forest and MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E5GEHzpFGYG"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import (\n",
        "    r2_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    median_absolute_error\n",
        ")\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# helper: regression metrics\n",
        "def regression_metrics(y_true, y_pred):\n",
        "    mse  = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae  = mean_absolute_error(y_true, y_pred)\n",
        "    medae = median_absolute_error(y_true, y_pred)\n",
        "\n",
        "    # MAPE: ignore zeros in y_true to avoid division-by-zero\n",
        "    y_true_nonzero = y_true[y_true != 0]\n",
        "    y_pred_nonzero = y_pred[y_true != 0]\n",
        "    if len(y_true_nonzero) > 0:\n",
        "        mape = np.mean(np.abs((y_true_nonzero - y_pred_nonzero) / y_true_nonzero)) * 100\n",
        "    else:\n",
        "        mape = np.nan\n",
        "\n",
        "    return {\n",
        "        \"R2\": r2_score(y_true, y_pred),\n",
        "        \"RMSE\": rmse,\n",
        "        \"MAE\": mae,\n",
        "        \"MedAE\": medae,\n",
        "        \"MAPE\": mape\n",
        "    }\n",
        "\n",
        "train_times_ms = {}\n",
        "pred_times_ms  = {}\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 6. RANDOM FOREST\n",
        "# -------------------------------------------------------------------\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=80,\n",
        "    max_depth=50,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# training time\n",
        "t0 = time.perf_counter()\n",
        "rf.fit(X_train, y_train)\n",
        "t1 = time.perf_counter()\n",
        "train_times_ms[\"RandomForest\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "# prediction times\n",
        "t0 = time.perf_counter()\n",
        "y_train_rf = rf.predict(X_train)\n",
        "t1 = time.perf_counter()\n",
        "pred_times_ms[\"RandomForest_train\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "y_val_rf   = rf.predict(X_val)\n",
        "t1 = time.perf_counter()\n",
        "pred_times_ms[\"RandomForest_val\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "y_test_rf = rf.predict(X_test)\n",
        "t1 = time.perf_counter()\n",
        "pred_times_ms[\"RandomForest_test\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "# metrics\n",
        "rf_train_metrics = regression_metrics(y_train, y_train_rf)\n",
        "rf_val_metrics   = regression_metrics(y_val,   y_val_rf)\n",
        "rf_test_metrics  = regression_metrics(y_test,  y_test_rf)\n",
        "\n",
        "print(\"\\n--- RANDOM FOREST ---\")\n",
        "\n",
        "# TRAIN: R2, RMSE, MAE\n",
        "print(\"Train R2:\",   rf_train_metrics[\"R2\"])\n",
        "print(\"Train RMSE:\", rf_train_metrics[\"RMSE\"])\n",
        "print(\"Train MAE:\",  rf_train_metrics[\"MAE\"])\n",
        "\n",
        "# VALIDATION: R2, RMSE, MAE, MAPE\n",
        "print(\"Val   R2:\",   rf_val_metrics[\"R2\"])\n",
        "print(\"Val   RMSE:\", rf_val_metrics[\"RMSE\"])\n",
        "print(\"Val   MAE:\",  rf_val_metrics[\"MAE\"])\n",
        "print(\"Val   MAPE (%):\", rf_val_metrics[\"MAPE\"])\n",
        "\n",
        "# TEST: full set\n",
        "print(\"Test  R2:\",    rf_test_metrics[\"R2\"])\n",
        "print(\"Test  RMSE:\",  rf_test_metrics[\"RMSE\"])\n",
        "print(\"Test  MAE:\",   rf_test_metrics[\"MAE\"])\n",
        "print(\"Test  MedAE:\", rf_test_metrics[\"MedAE\"])\n",
        "print(\"Test  MAPE (%):\", rf_test_metrics[\"MAPE\"])\n",
        "\n",
        "print(\"RF training time (ms):\", train_times_ms[\"RandomForest\"])\n",
        "print(\"RF prediction time (ms) - train:\", pred_times_ms[\"RandomForest_train\"])\n",
        "print(\"RF prediction time (ms) - val:  \", pred_times_ms[\"RandomForest_val\"])\n",
        "print(\"RF prediction time (ms) - test: \", pred_times_ms[\"RandomForest_test\"])\n",
        "\n",
        "# Random Forest feature importance chart\n",
        "# ---- Improved Feature Importance Plot (Top N Only) ----\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# sort by importance\n",
        "idx_sorted = np.argsort(importances)[::-1]\n",
        "\n",
        "# choose top N features (recommended: 15â€“25)\n",
        "N = 20\n",
        "top_features = feature_names[idx_sorted][:N]\n",
        "top_importances = importances[idx_sorted][:N]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "y_pos = np.arange(N)\n",
        "plt.barh(y_pos, top_importances, color=\"steelblue\")\n",
        "plt.yticks(y_pos, top_features)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(f\"Top {N} Most Important Features (Random Forest)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 7. MLP REGRESSOR\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "mlp = MLPRegressor(\n",
        "    hidden_layer_sizes=(256, 128, 64),\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    learning_rate=\"adaptive\",\n",
        "    max_iter=1,          # 1 iteration per .fit call\n",
        "    warm_start=True,     # keep weights between .fit calls\n",
        "    early_stopping=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "n_epochs = 30\n",
        "\n",
        "mlp_train_losses = []\n",
        "mlp_val_losses   = []\n",
        "\n",
        "# training time for full MLP training (all epochs)\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    # one \"epoch\" of training\n",
        "    mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # predictions for this epoch\n",
        "    y_train_epoch = mlp.predict(X_train_scaled)\n",
        "    y_val_epoch   = mlp.predict(X_val_scaled)\n",
        "\n",
        "    # use RMSE as the loss for plotting\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_epoch))\n",
        "    val_rmse   = np.sqrt(mean_squared_error(y_val,   y_val_epoch))\n",
        "\n",
        "    mlp_train_losses.append(train_rmse)\n",
        "    mlp_val_losses.append(val_rmse)\n",
        "\n",
        "    print(f\"Epoch {epoch}: train_RMSE={train_rmse:.4f}, val_RMSE={val_rmse:.4f}\")\n",
        "\n",
        "t1 = time.perf_counter()\n",
        "train_times_ms[\"MLP\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "# final predictions (after last epoch) for metrics\n",
        "y_train_nn = mlp.predict(X_train_scaled)\n",
        "y_val_nn   = mlp.predict(X_val_scaled)\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "y_test_nn = mlp.predict(X_test_scaled)\n",
        "t1 = time.perf_counter()\n",
        "pred_times_ms[\"MLP_test\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "# (re)compute the other prediction times if you still want them\n",
        "t0 = time.perf_counter()\n",
        "_ = mlp.predict(X_train_scaled)\n",
        "t1 = time.perf_counter()\n",
        "pred_times_ms[\"MLP_train\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "_ = mlp.predict(X_val_scaled)\n",
        "t1 = time.perf_counter()\n",
        "pred_times_ms[\"MLP_val\"] = (t1 - t0) * 1000.0\n",
        "\n",
        "# metrics using your regression_metrics helper\n",
        "mlp_train_metrics = regression_metrics(y_train, y_train_nn)\n",
        "mlp_val_metrics   = regression_metrics(y_val,   y_val_nn)\n",
        "mlp_test_metrics  = regression_metrics(y_test,  y_test_nn)\n",
        "\n",
        "print(\"\\n--- MLP ---\")\n",
        "print(\"Train R2:\",   mlp_train_metrics[\"R2\"])\n",
        "print(\"Train RMSE:\", mlp_train_metrics[\"RMSE\"])\n",
        "print(\"Train MAE:\",  mlp_train_metrics[\"MAE\"])\n",
        "\n",
        "print(\"Val   R2:\",   mlp_val_metrics[\"R2\"])\n",
        "print(\"Val   RMSE:\", mlp_val_metrics[\"RMSE\"])\n",
        "print(\"Val   MAE:\",  mlp_val_metrics[\"MAE\"])\n",
        "print(\"Val   MAPE (%):\", mlp_val_metrics[\"MAPE\"])\n",
        "\n",
        "print(\"Test  R2:\",    mlp_test_metrics[\"R2\"])\n",
        "print(\"Test  RMSE:\",  mlp_test_metrics[\"RMSE\"])\n",
        "print(\"Test  MAE:\",   mlp_test_metrics[\"MAE\"])\n",
        "print(\"Test  MedAE:\", mlp_test_metrics[\"MedAE\"])\n",
        "print(\"Test  MAPE (%):\", mlp_test_metrics[\"MAPE\"])\n",
        "\n",
        "print(\"MLP training time (ms):\", train_times_ms[\"MLP\"])\n",
        "print(\"MLP prediction time (ms) - train:\", pred_times_ms[\"MLP_train\"])\n",
        "print(\"MLP prediction time (ms) - val:  \", pred_times_ms[\"MLP_val\"])\n",
        "print(\"MLP prediction time (ms) - test: \", pred_times_ms[\"MLP_test\"])\n",
        "\n",
        "# MLP learning curve (Train vs Validation RMSE)\n",
        "epochs = np.arange(1, n_epochs + 1)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(epochs, mlp_train_losses, marker=\"o\", label=\"Train loss (RMSE)\")\n",
        "plt.plot(epochs, mlp_val_losses,   marker=\"s\", label=\"Validation loss (RMSE)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(\"MLP Learning Curve (Train vs Validation Loss)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 8. Summary of key metrics and times (Test set)\n",
        "# -------------------------------------------------------------------\n",
        "print(\"\\n--- SUMMARY: Random Forest vs MLP (Test set) ---\")\n",
        "print(\"Random Forest: R2 = {:.4f}, RMSE = {:.4f}, MAE = {:.4f}, MedAE = {:.4f}, MAPE = {:.2f}%\".format(\n",
        "    rf_test_metrics[\"R2\"],\n",
        "    rf_test_metrics[\"RMSE\"],\n",
        "    rf_test_metrics[\"MAE\"],\n",
        "    rf_test_metrics[\"MedAE\"],\n",
        "    rf_test_metrics[\"MAPE\"]\n",
        "))\n",
        "print(\"MLP:           R2 = {:.4f}, RMSE = {:.4f}, MAE = {:.4f}, MedAE = {:.4f}, MAPE = {:.2f}%\".format(\n",
        "    mlp_test_metrics[\"R2\"],\n",
        "    mlp_test_metrics[\"RMSE\"],\n",
        "    mlp_test_metrics[\"MAE\"],\n",
        "    mlp_test_metrics[\"MedAE\"],\n",
        "    mlp_test_metrics[\"MAPE\"]\n",
        "))\n",
        "\n",
        "print(\"\\nTraining times (ms):\")\n",
        "for model, t_ms in train_times_ms.items():\n",
        "    print(f\"{model}: {t_ms:.2f} ms\")\n",
        "\n",
        "print(\"\\nPrediction times on test set (ms):\")\n",
        "print(\"RandomForest:\", pred_times_ms[\"RandomForest_test\"])\n",
        "print(\"MLP:         \", pred_times_ms[\"MLP_test\"])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.19 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
